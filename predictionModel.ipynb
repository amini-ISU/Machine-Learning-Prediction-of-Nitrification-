{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error , accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "# from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "#import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#excel_file = 'Book1.xlsx'\n",
    "#excel_file = 'OTU level data for Random Forest_final.xlsx'\n",
    "#excel_file = 'OTU level data for Random Forest_Revised 7_18_19.xlsx'\n",
    "#excel_file = \"OTU level data for Random Forest COMPARTMENT_no_correlated.xlsx\"\n",
    "#excel_file = \"OTU level data for Random Forest CROPPING SYSTEM_no_correlated.xlsx\"\n",
    "#excel_file = 'OTU level data for Random Forest_Revised 7_18_19.xlsx'\n",
    "excel_file = 'OTU level data for Random Forest_Revised 7_18_19_del_AOA-B.xlsx'\n",
    "#excel_file ='OTU level data for Random Forest COMPARTMENT_no_correlated -delAOA-B.xlsx'\n",
    "#excel_file = 'OTU level data for Random Forest COMPARTMENT_no_correlated -delAOA-B.xlsx'\n",
    "data = pd.read_excel(excel_file, sheet_name =3, header=None)\n",
    "data= data.T\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data = data.drop(data.columns[0], 1)\n",
    "# #print(data)\n",
    "df = data.iloc[1:,:]\n",
    "df = df.iloc[:-1, :]\n",
    "#print(feature_train.shape)\n",
    "#print(response_train.shape)\n",
    "#print(feature_test.shape)\n",
    "#print(response_test.shape)\n",
    "#feature_train.shape\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.028177</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>1.580</td>\n",
       "      <td>25.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.020233</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>2.227</td>\n",
       "      <td>34.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>2.350</td>\n",
       "      <td>36.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>3.830</td>\n",
       "      <td>65.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>4.313</td>\n",
       "      <td>65.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.953</td>\n",
       "      <td>53.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.061</td>\n",
       "      <td>38.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>2.967</td>\n",
       "      <td>55.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>2.234</td>\n",
       "      <td>30.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>3.062</td>\n",
       "      <td>45.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>2.075</td>\n",
       "      <td>46.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.694</td>\n",
       "      <td>26.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.044956</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>2.132</td>\n",
       "      <td>36.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.051013</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>1.606</td>\n",
       "      <td>41.957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.006105  0.000379  0.001449  0.000138  0.028177  0.000655  0.001897   \n",
       "1   0.000934  0.000354  0.007120  0.021876  0.018783  0.000000  0.000741   \n",
       "2   0.001549  0.000344  0.008779  0.025949  0.020225  0.000043  0.000559   \n",
       "3   0.007677  0.000131  0.000394  0.000066  0.014698  0.004856  0.000919   \n",
       "4   0.003146  0.000000  0.000434  0.000000  0.006509  0.001410  0.000000   \n",
       "5   0.002162  0.000127  0.012145  0.050868  0.005214  0.000000  0.000064   \n",
       "6   0.002006  0.000251  0.007585  0.054601  0.004576  0.000188  0.000125   \n",
       "7   0.005659  0.000038  0.001633  0.000228  0.027876  0.000342  0.002089   \n",
       "8   0.004372  0.000201  0.001558  0.000352  0.025480  0.000503  0.002111   \n",
       "9   0.000913  0.000336  0.006441  0.017161  0.017930  0.000000  0.000721   \n",
       "10  0.003743  0.000110  0.000275  0.000000  0.012771  0.003303  0.000440   \n",
       "11  0.004831  0.000073  0.000512  0.000073  0.009808  0.003660  0.000659   \n",
       "12  0.001515  0.000144  0.009453  0.044956  0.004763  0.000000  0.000144   \n",
       "13  0.002261  0.000090  0.012482  0.051013  0.005608  0.000000  0.000090   \n",
       "\n",
       "          7         8         9   ...        29        30        31        32  \\\n",
       "0   0.006208  0.001104  0.000414  ...  0.000828  0.000414  0.000586  0.000069   \n",
       "1   0.020233  0.002964  0.001224  ...  0.000064  0.000193  0.000193  0.000032   \n",
       "2   0.020613  0.003615  0.001162  ...  0.000086  0.000215  0.000387  0.000000   \n",
       "3   0.001181  0.000459  0.000066  ...  0.000787  0.000328  0.000656  0.000656   \n",
       "4   0.000868  0.000108  0.000000  ...  0.001193  0.000325  0.000868  0.000325   \n",
       "5   0.003815  0.002861  0.000382  ...  0.000064  0.000318  0.000127  0.000000   \n",
       "6   0.003009  0.002884  0.000313  ...  0.000188  0.000752  0.000063  0.000000   \n",
       "7   0.006076  0.000949  0.000342  ...  0.000911  0.000646  0.000608  0.000038   \n",
       "8   0.006332  0.000653  0.000352  ...  0.001809  0.001005  0.000653  0.000050   \n",
       "9   0.018122  0.002692  0.001202  ...  0.000000  0.000336  0.000048  0.000000   \n",
       "10  0.000716  0.000220  0.000000  ...  0.001046  0.000110  0.000716  0.000110   \n",
       "11  0.001244  0.000366  0.000146  ...  0.001317  0.000220  0.000659  0.000366   \n",
       "12  0.002526  0.002093  0.000216  ...  0.000000  0.000216  0.000000  0.000000   \n",
       "13  0.002985  0.002171  0.000543  ...  0.000090  0.000362  0.000000  0.000000   \n",
       "\n",
       "          33        34        35        36     37      38  \n",
       "0   0.000138  0.000172  0.000103  0.000552  1.580  25.592  \n",
       "1   0.000129  0.000419  0.000097  0.003157  2.227  34.282  \n",
       "2   0.000172  0.000387  0.000215  0.004260  2.350  36.889  \n",
       "3   0.000000  0.000394  0.000000  0.000131  3.830  65.798  \n",
       "4   0.000000  0.000325  0.000217  0.000108  4.313  65.028  \n",
       "5   0.000382  0.000382  0.000254  0.004324  0.953  53.875  \n",
       "6   0.000251  0.000564  0.000063  0.003260  0.061  38.291  \n",
       "7   0.000000  0.000152  0.000038  0.000532  2.967  55.262  \n",
       "8   0.000050  0.000251  0.000101  0.000804  2.234  30.676  \n",
       "9   0.000433  0.000385  0.000096  0.002500  3.062  45.772  \n",
       "10  0.000110  0.000385  0.000055  0.000275  2.075  46.800  \n",
       "11  0.000073  0.000146  0.000000  0.000000  1.694  26.288  \n",
       "12  0.000505  0.000866  0.000794  0.002959  2.132  36.491  \n",
       "13  0.000090  0.001266  0.000633  0.003980  1.606  41.957  \n",
       "\n",
       "[14 rows x 39 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[1:,:-1].values\n",
    "y = data.iloc[1:,-1].values\n",
    "x=x.astype(float)\n",
    "y=y.astype(float)\n",
    "#x=np.array(x)\n",
    "x=pd.DataFrame(x)\n",
    "#xm =x.mean(axis =0, keepdims =True)\n",
    "#xc = x- xm\n",
    "#print(xm)\n",
    "#print(xc)\n",
    "#print(xc.shape)\n",
    "#m=np.matmul(np.transpose(xc),xc)\n",
    "#print(LA.eigvals(m/0.067))\n",
    "#x.corr()\n",
    "#xm\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35584840e+00,  1.59189742e+00, -8.05932953e-01,\n",
       "        -8.77196075e-01,  1.62574030e+00, -2.62396848e-01,\n",
       "         1.57648608e+00, -7.13337241e-02, -4.66548766e-01,\n",
       "        -9.73791717e-02, -3.29957239e-01, -7.73889792e-01,\n",
       "         1.02044156e+00, -4.89353121e-01, -1.98074358e-01,\n",
       "        -4.39847125e-03,  9.86535298e-01,  4.67567596e-01,\n",
       "        -5.67636697e-01,  2.66121883e+00,  1.89437182e+00,\n",
       "        -2.04786574e-01,  8.69769350e-01,  4.62434010e-01,\n",
       "         9.75028988e-01,  9.06586392e-01, -1.50006974e-01,\n",
       "         1.84968607e+00, -2.29131152e-01,  3.94883788e-01,\n",
       "         1.05496025e-01,  6.27577625e-01, -2.57936974e-01,\n",
       "        -1.80032620e-01, -9.04226428e-01, -3.81011682e-01,\n",
       "        -8.27103829e-01, -6.06261800e-01, -1.39158741e+00],\n",
       "       [-1.18733886e+00,  1.38807911e+00,  4.74462005e-01,\n",
       "         1.28889655e-01,  5.12527363e-01, -6.78507075e-01,\n",
       "        -1.82340505e-02,  1.92476514e+00,  1.11396958e+00,\n",
       "         1.84980691e+00,  1.17451775e+00,  1.73351332e-01,\n",
       "        -7.96698261e-01,  4.31639368e-01,  6.29278107e-01,\n",
       "         1.17282933e+00, -1.05273654e+00, -7.65946975e-01,\n",
       "        -6.16713807e-01,  2.66739909e-01, -6.16359485e-01,\n",
       "        -9.55187828e-01, -1.04683291e+00, -6.01765498e-01,\n",
       "        -7.93092445e-01, -2.23447238e-01, -6.42400661e-01,\n",
       "        -9.23675199e-01, -6.60579173e-01, -9.22507547e-01,\n",
       "        -8.17658081e-01, -6.78303791e-01, -4.52738964e-01,\n",
       "        -2.37022462e-01, -5.68272769e-02, -4.10853637e-01,\n",
       "         7.51205745e-01,  6.35749768e-03, -6.99754428e-01],\n",
       "       [-8.84896915e-01,  1.30531130e+00,  8.48847756e-01,\n",
       "         3.17369070e-01,  6.83418671e-01, -6.51180881e-01,\n",
       "        -2.68784330e-01,  1.97877992e+00,  1.66672277e+00,\n",
       "         1.69984546e+00,  8.47117001e-01,  4.78546729e-01,\n",
       "        -6.62446099e-01, -2.60030826e-01, -1.20601374e-02,\n",
       "         2.26207700e-01, -1.30873601e+00, -6.75645356e-01,\n",
       "         6.63679364e-01, -1.07606113e+00,  2.90115814e-01,\n",
       "        -5.63111843e-01, -1.31820247e-01, -6.54233315e-01,\n",
       "        -7.93092445e-01, -5.58860510e-01, -7.96786056e-01,\n",
       "        -9.22863934e-01, -5.10119977e-01, -8.85177688e-01,\n",
       "        -7.26187800e-01, -3.37136035e-02, -6.23479984e-01,\n",
       "         3.44639219e-02, -1.65314385e-01,  1.08431883e-01,\n",
       "         1.41923917e+00,  1.22821445e-01, -4.92204534e-01],\n",
       "       [ 2.12943738e+00, -4.33450098e-01, -1.04405797e+00,\n",
       "        -8.80543978e-01,  2.84051847e-02,  2.40485591e+00,\n",
       "         2.26810478e-01, -7.86763822e-01, -1.01391644e+00,\n",
       "        -9.34087590e-01, -1.11533904e+00, -8.77705617e-01,\n",
       "         1.57158190e+00,  2.64356079e-01, -5.91786142e-01,\n",
       "        -7.77603218e-01,  4.12618751e-01,  8.81254147e-01,\n",
       "        -2.49326814e-01, -1.07606113e+00,  9.77242383e-02,\n",
       "        -4.15973572e-01, -7.79855940e-01,  2.05056316e+00,\n",
       "         2.05333139e+00,  1.40313247e+00, -4.14319710e-01,\n",
       "        -2.04142214e-01,  1.02130953e+00,  3.25281448e-01,\n",
       "        -2.53549559e-01,  8.59714185e-01,  2.85385583e+00,\n",
       "        -1.04584305e+00, -1.43289667e-01, -8.34381537e-01,\n",
       "        -1.08186828e+00,  1.52417625e+00,  1.80931441e+00],\n",
       "       [-9.94200623e-02, -1.50458464e+00, -1.03497548e+00,\n",
       "        -8.83580814e-01, -9.42046974e-01,  2.17032021e-01,\n",
       "        -1.04062381e+00, -8.31343868e-01, -1.31195934e+00,\n",
       "        -1.09174013e+00, -1.47377761e+00, -1.02357749e+00,\n",
       "        -1.37066778e-01, -1.69692163e+00, -9.48916541e-01,\n",
       "        -1.37933823e+00,  6.18536437e-01,  1.23755293e-01,\n",
       "        -7.26919354e-01, -1.71789949e-01, -4.50694212e-01,\n",
       "        -1.15745091e+00, -1.37431287e+00,  5.67293665e-01,\n",
       "        -3.65278294e-01,  9.96306964e-01, -2.35335113e-03,\n",
       "        -6.05490530e-01,  2.66445581e+00,  1.02586547e+00,\n",
       "        -2.64573610e-01,  1.56316589e+00,  1.10123029e+00,\n",
       "        -1.04584305e+00, -3.78013606e-01,  1.16327869e-01,\n",
       "        -1.09564892e+00,  1.98151029e+00,  1.74801275e+00],\n",
       "       [-5.83511369e-01, -4.66618695e-01,  1.60871571e+00,\n",
       "         1.47065748e+00, -1.09551515e+00, -6.78507075e-01,\n",
       "        -9.52896157e-01, -4.11890451e-01,  1.02664912e+00,\n",
       "        -1.75115981e-01,  1.21646300e+00,  1.54522480e+00,\n",
       "        -1.01359352e+00,  6.59142153e-01, -9.48916541e-01,\n",
       "        -3.86129999e-01, -5.17610785e-01, -1.03583903e+00,\n",
       "        -6.25925748e-01, -1.07606113e+00, -6.34264576e-01,\n",
       "         1.79645172e+00, -1.30217359e+00, -1.13063233e+00,\n",
       "        -7.93092445e-01, -9.43624420e-01, -5.56062585e-01,\n",
       "        -4.70502076e-01, -9.61390430e-01, -9.23978429e-01,\n",
       "        -2.96073086e-01, -8.98084525e-01, -6.23479984e-01,\n",
       "         1.34852715e+00, -1.85217304e-01,  2.80089030e-01,\n",
       "         1.45771018e+00, -1.19994387e+00,  8.60094085e-01],\n",
       "       [-6.60182934e-01,  5.42066618e-01,  5.79424093e-01,\n",
       "         1.64344299e+00, -1.17108956e+00, -5.59085165e-01,\n",
       "        -8.67643272e-01, -5.26611126e-01,  1.04561876e+00,\n",
       "        -3.38660683e-01,  6.64471275e-01,  1.63415553e+00,\n",
       "        -8.88145766e-01,  9.68410994e-01, -2.66535990e-01,\n",
       "        -1.26430721e+00, -7.46809580e-01, -8.80623061e-01,\n",
       "         2.92185298e+00, -1.07606113e+00, -1.31164054e+00,\n",
       "         6.52859438e-01, -5.83073343e-01, -1.13063233e+00,\n",
       "        -7.93092445e-01, -9.43624420e-01,  7.02206102e-01,\n",
       "        -2.57034228e-01, -8.18108288e-01, -7.09135399e-01,\n",
       "         1.52188212e+00, -1.11234988e+00, -6.23479984e-01,\n",
       "         5.27888984e-01,  4.43057056e-01, -5.59693745e-01,\n",
       "         8.13208655e-01, -2.04454420e+00, -3.80587751e-01],\n",
       "       [ 1.13657473e+00, -1.19460609e+00, -7.64275490e-01,\n",
       "        -8.73034755e-01,  1.59002492e+00, -4.61460440e-01,\n",
       "         1.84126831e+00, -9.00460060e-02, -5.97534983e-01,\n",
       "        -2.70517161e-01, -9.07836912e-02, -8.55411508e-01,\n",
       "         9.41597186e-01,  1.68144595e+00,  1.73820794e+00,\n",
       "         9.85282240e-01,  1.76680696e+00,  2.37094847e+00,\n",
       "         2.26201041e-01,  5.06782615e-01, -3.74348026e-01,\n",
       "         1.30017999e-01,  1.43241247e+00,  6.67103757e-01,\n",
       "         1.00414618e+00,  2.11248031e+00,  1.07198934e+00,\n",
       "         1.90302297e+00, -2.28192654e-01,  5.39420847e-01,\n",
       "         1.07556829e+00,  6.98490581e-01, -4.22216842e-01,\n",
       "        -1.04584305e+00, -9.74836738e-01, -6.67968577e-01,\n",
       "        -8.39295261e-01,  7.07034901e-01,  9.70516679e-01],\n",
       "       [ 5.03783416e-01,  1.36192365e-01, -7.81231581e-01,\n",
       "        -8.67299295e-01,  1.30609524e+00, -3.59376456e-01,\n",
       "         1.87158323e+00, -5.36392233e-02, -8.49096081e-01,\n",
       "        -2.46510827e-01, -3.61058530e-01, -8.66137463e-01,\n",
       "         4.62627005e-01,  1.75717921e+00,  2.60695212e+00,\n",
       "         6.19706571e-01,  7.98312845e-01,  1.53836597e+00,\n",
       "         1.80663224e-01,  1.80684030e-01, -1.26625565e+00,\n",
       "         4.14533782e-02,  1.89317577e+00,  1.15238464e+00,\n",
       "        -3.31193831e-04,  8.53771047e-01,  3.10874207e+00,\n",
       "         1.15215584e+00,  5.22656478e-01,  2.08888493e+00,\n",
       "         2.58030056e+00,  8.50290537e-01, -3.57148705e-01,\n",
       "        -7.30432287e-01, -6.33090737e-01, -3.93953388e-01,\n",
       "        -6.74287426e-01,  1.29855272e-02, -9.86837250e-01],\n",
       "       [-1.19767300e+00,  1.24186138e+00,  3.21195657e-01,\n",
       "        -8.93466459e-02,  4.11405039e-01, -6.78507075e-01,\n",
       "        -4.57965582e-02,  1.62434240e+00,  8.82737771e-01,\n",
       "         1.79561345e+00,  8.12562605e-01,  5.86637843e-02,\n",
       "        -8.85475954e-01, -1.13954628e+00,  9.75993032e-02,\n",
       "        -1.13605817e+00, -7.82303306e-01, -1.06169567e+00,\n",
       "        -4.03929107e-01,  9.27393113e-01, -7.91906953e-01,\n",
       "        -7.34964822e-01,  2.48209969e-01, -7.26923437e-01,\n",
       "        -7.93092445e-01, -7.28724075e-01, -3.98162777e-01,\n",
       "        -6.94657866e-01, -4.40040499e-01, -1.03372181e+00,\n",
       "        -2.18365378e-01, -1.16092402e+00, -6.23479984e-01,\n",
       "         1.66936101e+00, -1.74726477e-01, -4.13113484e-01,\n",
       "         3.52763567e-01,  7.96986730e-01,  2.14993667e-01],\n",
       "       [ 1.94359502e-01, -6.05977880e-01, -1.07080043e+00,\n",
       "        -8.83580814e-01, -1.99959136e-01,  1.41883777e+00,\n",
       "        -4.33030391e-01, -8.53011527e-01, -1.21706031e+00,\n",
       "        -1.09174013e+00, -1.53011684e+00, -9.47717682e-01,\n",
       "         1.51809194e+00, -1.03796608e+00, -5.00944651e-02,\n",
       "         1.31035707e-01,  4.63717107e-01,  1.42565265e-01,\n",
       "        -7.18205000e-01, -6.17205478e-01,  1.69222696e+00,\n",
       "        -8.80985359e-01, -9.30085434e-02,  6.55572339e-01,\n",
       "         1.81194389e+00, -6.97528864e-01, -5.68794783e-01,\n",
       "        -7.92672427e-01,  1.06114436e+00,  7.71449863e-01,\n",
       "        -1.16596823e+00,  1.05727488e+00, -4.00318084e-02,\n",
       "        -3.54877141e-01, -1.72060028e-01, -5.93171603e-01,\n",
       "        -9.94638550e-01, -1.37565428e-01,  2.96835359e-01],\n",
       "       [ 7.29202874e-01, -9.07201547e-01, -1.01727704e+00,\n",
       "        -8.80193463e-01, -5.51159258e-01,  1.64530946e+00,\n",
       "        -1.31801824e-01, -7.77778522e-01, -1.09323311e+00,\n",
       "        -7.40042160e-01, -1.41996073e+00, -9.63054862e-01,\n",
       "         1.02622661e+00, -7.95492514e-01, -5.50565719e-01,\n",
       "         1.37067264e+00,  1.39439368e+00,  1.99934387e-01,\n",
       "        -1.31323402e+00,  1.44105998e-01,  1.36154898e+00,\n",
       "        -7.89868886e-01,  1.31496390e+00,  8.81043660e-01,\n",
       "         7.28061520e-02, -2.89218818e-01, -2.71195401e-01,\n",
       "         1.96993121e-01,  4.18599863e-01,  1.24006978e+00,\n",
       "        -7.07744694e-01,  8.68172032e-01,  1.31586708e+00,\n",
       "        -5.86497126e-01, -9.93860249e-01, -8.34381537e-01,\n",
       "        -1.16136136e+00, -4.98319605e-01, -1.33617708e+00],\n",
       "       [-9.01531147e-01, -3.26630360e-01,  1.00106968e+00,\n",
       "         1.19704417e+00, -1.14900467e+00, -6.78507075e-01,\n",
       "        -8.41505211e-01, -5.95410701e-01,  3.73646016e-01,\n",
       "        -5.71616446e-01,  7.29046855e-01,  1.08132491e+00,\n",
       "        -1.15352795e+00, -4.89570803e-01, -5.56171031e-01,\n",
       "        -1.13530232e+00, -1.35618279e+00, -8.41157041e-01,\n",
       "         8.31777337e-01,  7.28435564e-01, -4.54093250e-01,\n",
       "         2.19483850e+00, -4.00231168e-01, -1.13063233e+00,\n",
       "        -7.93092445e-01, -9.43624420e-01, -5.59480002e-01,\n",
       "        -1.12852189e+00, -9.41505310e-01, -1.03372181e+00,\n",
       "        -7.20676834e-01, -1.32065495e+00, -6.23479984e-01,\n",
       "         2.12433327e+00,  1.48076272e+00,  2.64375500e+00,\n",
       "         6.30760902e-01, -8.35943312e-02, -5.23890325e-01],\n",
       "       [-5.34652013e-01, -7.66338873e-01,  1.68483604e+00,\n",
       "         1.47737247e+00, -1.04884197e+00, -6.78507075e-01,\n",
       "        -9.15832495e-01, -5.30058498e-01,  4.40005022e-01,\n",
       "         2.12144456e-01,  8.76815191e-01,  1.33622734e+00,\n",
       "        -1.00361187e+00,  1.46707496e-01, -9.48916541e-01,\n",
       "         1.57740343e+00, -6.76542068e-01, -4.63484003e-01,\n",
       "         3.97716608e-01, -3.22120125e-01,  5.63574870e-01,\n",
       "         8.86708751e-01, -4.72228485e-02, -1.06157599e+00,\n",
       "        -7.93092445e-01, -9.43624420e-01, -5.23375208e-01,\n",
       "         8.97702354e-01, -8.99098568e-01, -8.77613439e-01,\n",
       "        -1.12449723e-01, -1.32065495e+00, -6.23479984e-01,\n",
       "        -4.78183557e-01,  2.85764312e+00,  1.93992541e+00,\n",
       "         1.24931540e+00, -5.81643405e-01, -8.87281768e-02]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_img = scaler.transform(x)\n",
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an instance of the Model\n",
    "pca = PCA(0.8)\n",
    "pca.fit(train_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-1ebe9049ee91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1st Comp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2nd Comp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3rd Comp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4st Comp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5thComp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6st Comp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#plt.tight_layout()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "plt.yticks([0,1,2,3,4,5],['1st Comp','2nd Comp','3rd Comp','4st Comp','5thComp','6st Comp'],fontsize=10)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(a.columns)),a.columns,rotation=90,ha='left')\n",
    "#plt.tight_layout()\n",
    "plt.show()# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def eigenvalue (input_matrix):\n",
    "    xm = input_matrix.mean(axis = 0)\n",
    "    xc=input_matrix-xm\n",
    "    cov = (1/(x.shape[0]-1))*(np.matmul(np.transpose(xc),xc))\n",
    "    imp = LA.eigvals(cov)\n",
    "    return imp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 37 29 28 36 34 33 35 27 26 25 24 19 18 17 16 15 11 12 10  9  8  7  6\n",
      "  5  4  3  2  1  0]\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.91748089e+01+0.00000000e+00j,  7.25462916e+00+0.00000000e+00j,\n",
       "        4.40968492e+00+0.00000000e+00j,  3.00501731e+00+0.00000000e+00j,\n",
       "        1.82700491e+00+0.00000000e+00j,  1.70943672e+00+0.00000000e+00j,\n",
       "        1.53516810e+00+0.00000000e+00j,  8.43848576e-01+0.00000000e+00j,\n",
       "        7.57780334e-01+0.00000000e+00j,  5.66806855e-01+0.00000000e+00j,\n",
       "        3.77767919e-01+0.00000000e+00j,  2.48843342e-01+0.00000000e+00j,\n",
       "        2.89202973e-01+0.00000000e+00j, -7.14902248e-16+4.75780835e-16j,\n",
       "       -7.14902248e-16-4.75780835e-16j,  8.31954910e-16+0.00000000e+00j,\n",
       "        6.57649611e-16+0.00000000e+00j,  5.37679818e-16+0.00000000e+00j,\n",
       "        4.46241365e-16+9.74911956e-17j,  4.46241365e-16-9.74911956e-17j,\n",
       "       -5.21060743e-16+3.29934788e-17j, -5.21060743e-16-3.29934788e-17j,\n",
       "       -4.73970390e-16+0.00000000e+00j, -4.06563436e-16+0.00000000e+00j,\n",
       "        4.13719664e-16+0.00000000e+00j,  3.03931924e-16+0.00000000e+00j,\n",
       "        2.43451599e-16+9.95026376e-17j,  2.43451599e-16-9.95026376e-17j,\n",
       "       -8.28730110e-17+2.16602184e-16j, -8.28730110e-17-2.16602184e-16j,\n",
       "       -2.90903778e-16+0.00000000e+00j, -2.06651544e-16+1.07091150e-16j,\n",
       "       -2.06651544e-16-1.07091150e-16j,  8.56327092e-17+1.41327209e-16j,\n",
       "        8.56327092e-17-1.41327209e-16j,  1.20891190e-16+0.00000000e+00j,\n",
       "        7.67090827e-17+0.00000000e+00j, -1.11697697e-16+2.87149946e-17j,\n",
       "       -1.11697697e-16-2.87149946e-17j])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=eigenvalue(train_img)\n",
    "ind = np.argpartition(E,-30)[-30:]\n",
    "print(ind[np.argsort(E[ind])])\n",
    "print(np.argmin(E))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img = pca.transform(train_img)\n",
    "train_img.shape\n",
    "# eigenvalue(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_error(X_train, y_train, model):\n",
    "    '''returns in-sample error for already fit model.'''\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "    \n",
    "def calc_validation_error(X_test, y_test, model):\n",
    "    '''returns out-of-sample error for already fit model.'''\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "    \n",
    "def calc_metrics(X_train, y_train, X_test, y_test, model):\n",
    "    '''fits model and returns the RMSE for in-sample error and out-of-sample error'''\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error = calc_train_error(X_train, y_train, model)\n",
    "    validation_error = calc_validation_error(X_test, y_test, model)\n",
    "    return train_error, validation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "sv = SVR(kernel='linear', C=1, degree = 1)\n",
    "tr =  DecisionTreeRegressor(max_features=1, max_depth=2, random_state=20)\n",
    "rf = RandomForestRegressor(n_estimators=63, max_features=1, max_depth=2, random_state=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(train_img,y)\n",
    "model2 = sv.fit(train_img,y)\n",
    "model3 = tr.fit(train_img,y)\n",
    "model4= rf.fit(train_img,y)\n",
    "\n",
    "pred_train= model.predict(train_img)\n",
    "pred_train2= model2.predict(train_img)\n",
    "pred_train3= model3.predict(train_img)\n",
    "pred_train4= model4.predict(train_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "5.1470073282927205\n",
      "1.0\n",
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\famini\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#parameter tuning decision tree\n",
    "stat_mf =[]\n",
    "stat_md =[]\n",
    "for i in range(1,10):    \n",
    "    # Number of features to consider at every split\n",
    "    max_features = [int(x) for x in np.linspace(start=1, stop=x.shape[1], num=1)]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(2, stop =10, num = 1)]\n",
    "    #max_depth.append(None)\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'max_features': max_features,\n",
    "                   'max_depth': max_depth\n",
    "                    }\n",
    "\n",
    "    # fit model\n",
    "    tr_random = RandomizedSearchCV(estimator = tr, param_distributions = random_grid, cv=3, random_state=None, n_jobs = 1)\n",
    "    tr_random.fit(train_img,y)\n",
    "    stat_mf.append(tr_random.best_estimator_.max_features)\n",
    "    stat_md.append(tr_random.best_estimator_.max_depth)\n",
    "    best_random = tr_random.best_estimator_\n",
    "    # evaluate model\n",
    "    predictions_train = best_random.predict(train_img)\n",
    "    score_train = sqrt(mean_squared_error(y, predictions_train))\n",
    "    print(score_train)\n",
    "print(np.mean(stat_mf))\n",
    "print(np.mean(stat_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.065855944543755\n",
      "5.025714829552343\n",
      "5.097848790422886\n",
      "5.007039931653845\n",
      "5.06899680310517\n",
      "5.065855944543755\n",
      "5.097848790422886\n",
      "5.085561601187083\n",
      "5.097848790422886\n",
      "97.77777777777777\n",
      "1.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#parameter tuning random forest\n",
    "stat_n=[]\n",
    "stat_mf =[]\n",
    "stat_md =[]\n",
    "for i in range(1,10):    \n",
    "    n_estimators = [int(x) for x in np.linspace(start = 50, stop = 100, num = 100)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = [int(x) for x in np.linspace(start=1, stop=x.shape[1], num=1)]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(2, stop =10, num = 1)]\n",
    "    #max_depth.append(None)\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth\n",
    "                    }\n",
    "\n",
    "\n",
    "    # fit model\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, cv=3, random_state=None, n_jobs = 1)\n",
    "    rf_random.fit(train_img,y )\n",
    "    stat_n.append(rf_random.best_estimator_.n_estimators)\n",
    "    stat_mf.append(rf_random.best_estimator_.max_features)\n",
    "    stat_md.append(rf_random.best_estimator_.max_depth)\n",
    "    best_random = rf_random.best_estimator_\n",
    "    # evaluate model\n",
    "    predictions_train = best_random.predict(train_img)\n",
    "    score_train = sqrt(mean_squared_error(y, predictions_train))\n",
    "    print(score_train)\n",
    "print(np.mean(stat_n))\n",
    "print(np.mean(stat_mf))\n",
    "print(np.mean(stat_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'param_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ae5badf6bcaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0msv_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0msv_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mstat_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msv_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'param_distributions'"
     ]
    }
   ],
   "source": [
    "#parameter tuning SVR\n",
    "stat_c=[]\n",
    "stat_degree =[]\n",
    "for i in range(1,10):    \n",
    "    # Number of features to consider at every split\n",
    "    kernel = ['linear']\n",
    "    C = [int(x) for x in np.linspace(start=1, stop=10, num=1)]\n",
    "    # Maximum number of levels in tree\n",
    "    degree = [int(x) for x in np.linspace(start =1, stop =3, num = 1)]\n",
    "    #max_depth.append(None)\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'C': C,\n",
    "                   'degree': degree,\n",
    "                    }\n",
    "\n",
    "    # fit model\n",
    "    sv_random = GridSearchCV(estimator = sv, param_distributions = random_grid, cv=3, random_state=None, n_jobs = 1)\n",
    "    sv_random.fit(train_img, y)\n",
    "    stat_c.append(sv_random.best_estimator_.C)\n",
    "    stat_degree.append(sv_random.best_estimator_.degree)\n",
    "    best_random = sv_random.best_estimator_\n",
    "    # evaluate model\n",
    "    predictions_train = best_random.predict(train_img)\n",
    "    score_train = sqrt(mean_squared_error(y, predictions_train))\n",
    "    print(score_train)\n",
    "\n",
    "print(np.mean(stat_c))\n",
    "print(np.mean(stat_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train_SD_lm: 69.7 %.\n",
      "Accuracy_train_SD_SVM: 75.63 %.\n",
      "Accuracy_train_SD_DT: 75.84 %.\n",
      "Accuracy_train_SD_RF: 70.95 %.\n",
      "6.079970254410943\n",
      "6.422629348729665\n",
      "5.53402154525435\n",
      "5.489890206905482\n"
     ]
    }
   ],
   "source": [
    "errors1 = abs(pred_train - y)\n",
    "errors2 = abs(pred_train2 - y)\n",
    "errors3 = abs(pred_train3- y)\n",
    "errors4 = abs(pred_train4 - y)\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors1 / y)\n",
    "mape2 = 100 * (errors2 / y)\n",
    "mape3 = 100 * (errors3 / y)\n",
    "mape4 = 100 * (errors4 / y)\n",
    "\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "accuracy2 = 100 - np.mean(mape2)\n",
    "accuracy3 = 100 - np.mean(mape3)\n",
    "accuracy4 = 100 - np.mean(mape4)\n",
    "\n",
    "\n",
    "print('Accuracy_train_SD_lm:', round(accuracy, 2), '%.')\n",
    "print('Accuracy_train_SD_SVM:', round(accuracy2, 2), '%.')\n",
    "print('Accuracy_train_SD_DT:', round(accuracy3, 2), '%.')\n",
    "print('Accuracy_train_SD_RF:', round(accuracy4, 2), '%.')\n",
    "#print(lm.score(train_img, y))\n",
    "print(sqrt(mean_squared_error(y, pred_train)))\n",
    "print(sqrt(mean_squared_error(y, pred_train2)))\n",
    "print(sqrt(mean_squared_error(y, pred_train3)))\n",
    "print(sqrt(mean_squared_error(y, pred_train4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =      2| mean val error : 7.497085342088541\n",
      "k =      3| mean val error : 7.851677206006418\n",
      "k =      4| mean val error : 7.654369490696662\n",
      "k =      5| mean val error : 7.336563253078813\n",
      "k =      6| mean val error : 7.06372841917808\n",
      "k =      7| mean val error : 7.1680084374179165\n",
      "k =      8| mean val error : 6.700544565371025\n",
      "k =      9| mean val error : 6.64622081955519\n",
      "k =     10| mean val error : 6.447335737937161\n"
     ]
    }
   ],
   "source": [
    "#linear regression-cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "for K in range(2,11):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "\n",
    "    validation_errors = []\n",
    "    for train_index, val_index in kf.split(x,y):\n",
    "\n",
    "            # split data\n",
    "            X_train, X_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            #calculate errors\n",
    "            pca = PCA(0.8)\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_val = pca.transform(X_val)\n",
    "            m = lm.fit(X_train, y_train)\n",
    "            m= sv.fit(X_train, y_train)\n",
    "            m= tr.fit(X_train, y_train)\n",
    "            m = rf.fit(X_train, y_train)\n",
    "            pred_test = m.predict(X_val)\n",
    "            errors1 = abs(pred_test - y_val)\n",
    "            # Calculate mean absolute percentage error (MAPE)\n",
    "            mape = 100 * (errors1 / y_val)\n",
    "\n",
    "\n",
    "            # Calculate and display accuracy\n",
    "            accuracy = 100 - np.mean(mape)\n",
    "            #print('Accuracy_test_RC:', round(accuracy, 2), '%.')\n",
    "            \n",
    "            val_error = calc_validation_error(X_val, y_val, m)\n",
    "\n",
    "            # append to appropriate list\n",
    "            validation_errors.append(val_error)\n",
    "            #print(validation_errors)\n",
    "\n",
    "    print('k ={:7}| mean val error : {:5}'.\n",
    "          format (K, np.mean(validation_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.443883447755724\n",
      "7.439296198831198\n"
     ]
    }
   ],
   "source": [
    "#accuracy test 10 fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_test =[]\n",
    "accuracy_mean = []\n",
    "validation_errors = []\n",
    "val_mean = []\n",
    "for iteration in range(30):\n",
    "    for train_index, val_index in kf.split(x,y):\n",
    "    \n",
    "    # split data\n",
    "            X_train, X_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            #calculate errors\n",
    "            pca = PCA(0.8)\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_val = pca.transform(X_val)\n",
    "            m = lm.fit(X_train, y_train)\n",
    "            #m= sv.fit(X_train, y_train)\n",
    "            #m= tr.fit(X_train, y_train)\n",
    "            #m = rf.fit(X_train, y_train)\n",
    "            pred_test = m.predict(X_val)\n",
    "            errors1 = abs(pred_test - y_val)\n",
    "            # Calculate mean absolute percentage error (MAPE)\n",
    "            mape = 100 * (errors1 / y_val)\n",
    "            # Calculate and display accuracy\n",
    "            accuracy = 100 - np.mean(mape)\n",
    "            accuracy_test.append(accuracy)\n",
    "            val_error = calc_validation_error(X_val, y_val, m)\n",
    "\n",
    "            # append to appropriate list\n",
    "            validation_errors.append(val_error)\n",
    "            \n",
    "    accuracy_mean.append(accuracy_test)\n",
    "    val_mean.append(validation_errors)\n",
    "    \n",
    "print(np.mean(accuracy_mean))\n",
    "print(np.mean(val_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.5474013195426\n",
      "7.381800985938063\n"
     ]
    }
   ],
   "source": [
    "#accuracy test 10 fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_test =[]\n",
    "accuracy_mean = []\n",
    "validation_errors = []\n",
    "val_mean = []\n",
    "for iteration in range(30):\n",
    "    for train_index, val_index in kf.split(x,y):\n",
    "    \n",
    "    # split data\n",
    "            X_train, X_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            #calculate errors\n",
    "            pca = PCA(0.8)\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_val = pca.transform(X_val)\n",
    "            m = lm.fit(X_train, y_train)\n",
    "            m= sv.fit(X_train, y_train)\n",
    "            #m= tr.fit(X_train, y_train)\n",
    "            #m = rf.fit(X_train, y_train)\n",
    "            pred_test = m.predict(X_val)\n",
    "            errors1 = abs(pred_test - y_val)\n",
    "            # Calculate mean absolute percentage error (MAPE)\n",
    "            mape = 100 * (errors1 / y_val)\n",
    "            # Calculate and display accuracy\n",
    "            accuracy = 100 - np.mean(mape)\n",
    "            accuracy_test.append(accuracy)\n",
    "            val_error = calc_validation_error(X_val, y_val, m)\n",
    "\n",
    "            # append to appropriate list\n",
    "            validation_errors.append(val_error)\n",
    "            \n",
    "    accuracy_mean.append(accuracy_test)\n",
    "    val_mean.append(validation_errors)\n",
    "    \n",
    "print(np.mean(accuracy_mean))\n",
    "print(np.mean(val_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.73334555485391\n",
      "6.075627131226218\n"
     ]
    }
   ],
   "source": [
    "#accuracy test 10 fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_test =[]\n",
    "accuracy_mean = []\n",
    "validation_errors = []\n",
    "val_mean = []\n",
    "for iteration in range(30):\n",
    "    for train_index, val_index in kf.split(x,y):\n",
    "    \n",
    "    # split data\n",
    "            X_train, X_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            #calculate errors\n",
    "            pca = PCA(0.8)\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_val = pca.transform(X_val)\n",
    "            m = lm.fit(X_train, y_train)\n",
    "            m= sv.fit(X_train, y_train)\n",
    "            m= tr.fit(X_train, y_train)\n",
    "            #m = rf.fit(X_train, y_train)\n",
    "            pred_test = m.predict(X_val)\n",
    "            errors1 = abs(pred_test - y_val)\n",
    "            # Calculate mean absolute percentage error (MAPE)\n",
    "            mape = 100 * (errors1 / y_val)\n",
    "            # Calculate and display accuracy\n",
    "            accuracy = 100 - np.mean(mape)\n",
    "            accuracy_test.append(accuracy)\n",
    "            val_error = calc_validation_error(X_val, y_val, m)\n",
    "\n",
    "            # append to appropriate list\n",
    "            validation_errors.append(val_error)\n",
    "            \n",
    "    accuracy_mean.append(accuracy_test)\n",
    "    val_mean.append(validation_errors)\n",
    "    \n",
    "print(np.mean(accuracy_mean))\n",
    "print(np.mean(val_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.169041888930344\n",
      "6.44733573793716\n"
     ]
    }
   ],
   "source": [
    "#accuracy test 10 fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_test =[]\n",
    "accuracy_mean = []\n",
    "validation_errors = []\n",
    "val_mean = []\n",
    "for iteration in range(30):\n",
    "    for train_index, val_index in kf.split(x,y):\n",
    "    \n",
    "    # split data\n",
    "            X_train, X_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            #calculate errors\n",
    "            pca = PCA(0.8)\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_val = pca.transform(X_val)\n",
    "            m = lm.fit(X_train, y_train)\n",
    "            m= sv.fit(X_train, y_train)\n",
    "            m= tr.fit(X_train, y_train)\n",
    "            m = rf.fit(X_train, y_train)\n",
    "            pred_test = m.predict(X_val)\n",
    "            errors1 = abs(pred_test - y_val)\n",
    "            # Calculate mean absolute percentage error (MAPE)\n",
    "            mape = 100 * (errors1 / y_val)\n",
    "            # Calculate and display accuracy\n",
    "            accuracy = 100 - np.mean(mape)\n",
    "            accuracy_test.append(accuracy)\n",
    "            val_error = calc_validation_error(X_val, y_val, m)\n",
    "\n",
    "            # append to appropriate list\n",
    "            validation_errors.append(val_error)\n",
    "            \n",
    "    accuracy_mean.append(accuracy_test)\n",
    "    val_mean.append(validation_errors)\n",
    "    \n",
    "print(np.mean(accuracy_mean))\n",
    "print(np.mean(val_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.79461734804402, 7.7971456997899065, 13.396710100442192, 13.159214995021959, 6.423217265665737, 12.326000617145588, 12.072960807761214, 17.327215388663802, 7.261482183182672, 14.672787951993442, 11.461825414984244, 7.631034579123653, 8.27569557507477, 12.656793330753208, 13.246204080257986, 11.96876474145695, 14.09785638199915, 12.490338179327045, 11.885854854883064, 6.928449370027058, 7.960638938239469, 8.288908583282264, 15.823497331113845, 8.28378612151879, 15.253886494421026, 11.52514241796418, 10.357284083250661, 12.699003039033062, 11.39396784075737, 11.480892319162246, 14.022116714284321, 11.825900147900999, 9.993395554120866, 9.162085046979374, 9.693630318611783, 8.307816680326264, 14.998494766801354, 14.97716993525186, 13.343853012894801, 9.453052800559957, 8.709899720983822, 5.812813853300946, 5.7705314114635575, 11.280932778768562, 4.658580814072728, 10.794951750811125, 8.044706728998552, 8.300578919764696, 11.545321326085762, 13.935587129700313, 5.308788450001211, 8.543021029704, 12.957290350047165, 13.999983511770111, 9.607049573638129, 5.069861906746385, 12.722102705960069, 13.082505878192295, 12.959176506794714, 10.732933829366058, 10.487968938884451, 11.857208046570069, 11.856582498207224, 11.014156452531482, 11.035043363792443, 15.201476979837402, 14.263719031859914, 11.727013990498206, 12.815538570770824, 14.963873641654164, 15.21849265905294, 10.70751559889217, 13.654116373361264, 14.774024532006257, 12.318650876843671, 12.926593061672236, 12.15124861903612, 12.531559349223095, 4.622999163867648, 7.211371961708247, 2.7227363148829515, 15.97576425197817, 10.441391799710749, 9.863576299329866, 15.760948344288616, 7.536775547878497, 7.564560868148555, 12.671813714901702, 7.89992549485412, 14.089548802988215, 13.512299102525942, 9.501524948055394, 12.631711674260774, 12.073604217104895, 15.468001130495342, 11.484729510454502, 9.903579810059833, 9.78056399623529, 12.620913247259754, 7.736305530574175]\n",
      "95.0 confidence interval 9.3% and 13.0%\n",
      "11.161347375044995\n"
     ]
    }
   ],
   "source": [
    "#bootstrap for evaluating linear regression\n",
    "n_iteration = 100\n",
    "n_size = int(len(df)*0.7)\n",
    "values = df.values\n",
    "values.astype(float)\n",
    "stats = []\n",
    "accuracy_test =[]\n",
    "for i in range(n_iteration):\n",
    "    train = resample(values, n_samples = n_size)\n",
    "    test = np.array([x for x in values if x.tolist() not in train.tolist()])\n",
    "    #print(\"train set:\", train.shape)\n",
    "    #print(\"test set:\",test.shape)\n",
    "    tr = DecisionTreeRegressor()\n",
    "    #B = BayesianRidge()\n",
    "    #model = B.fit(train[:,:-1],train[:,-1])\n",
    "    #model = lm.fit(train[:,:-1],train[:,-1])\n",
    "    model = RandomForestRegressor().fit(train[:,:-1],train[:,-1])\n",
    "    pred_test = model.predict(test[:,:-1])\n",
    "    #print(test[:,-1])\n",
    "    #print (pred_test)\n",
    "    errors1 = abs(pred_test - test[:,-1])\n",
    "    #print(errors1)\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors1 / test[:,-1])\n",
    "    #print(mape)\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    #print('Accuracy_test_RC:', round(accuracy, 2), '%.')\n",
    "    accuracy_test.append(accuracy)\n",
    "    \n",
    "    #score_train = sqrt(mean_squared_error(train[:,-1], pred_train))\n",
    "    score_test = sqrt(mean_squared_error(test[:,-1], pred_test))\n",
    "    #ACC = 0.632*score_train + 0.368*score_test\n",
    "    stats.append(score_test)\n",
    "    \n",
    "plt.hist(stats) \n",
    "plt.show()\n",
    "\n",
    "#confident interval\n",
    "z = 1.96\n",
    "xbar = np.mean(stats)\n",
    "var = np.var(stats)\n",
    "#print(stats)\n",
    "lower =  max(0,xbar - (z*var/(sqrt(n_iteration))))\n",
    "upper =  xbar + (z*var/(sqrt(n_iteration)))\n",
    "print ('%.1f confidence interval %.1f%% and %.1f%%' % (95, lower,upper))\n",
    "print(np.mean(stats))\n",
    "#print(np.mean(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12   -0.524188\n",
       "37   -0.428933\n",
       "16   -0.422456\n",
       "38   -0.412172\n",
       "7    -0.402207\n",
       "22   -0.395082\n",
       "8    -0.389898\n",
       "29   -0.371767\n",
       "14   -0.331003\n",
       "17   -0.300845\n",
       "27   -0.292685\n",
       "24   -0.273943\n",
       "39   -0.262376\n",
       "4    -0.257590\n",
       "11   -0.222402\n",
       "28   -0.191854\n",
       "21   -0.180298\n",
       "5    -0.137261\n",
       "33   -0.115864\n",
       "34   -0.072382\n",
       "13   -0.069903\n",
       "26   -0.066147\n",
       "15   -0.059983\n",
       "19   -0.039880\n",
       "9    -0.026713\n",
       "25    0.009586\n",
       "36    0.045071\n",
       "35    0.052388\n",
       "2     0.072506\n",
       "30    0.072966\n",
       "32    0.106197\n",
       "0     0.152207\n",
       "40    0.182089\n",
       "20    0.317188\n",
       "1     0.353887\n",
       "3     0.356283\n",
       "10    0.367523\n",
       "18    0.415171\n",
       "31    0.484262\n",
       "6     0.536639\n",
       "23    0.649173\n",
       "41    1.000000\n",
       "Name: 41, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear feature selection\n",
    "\n",
    "df1=np.array(a)\n",
    "y1=y.reshape(-1,1)\n",
    "s=np.concatenate((df1,y1) , axis=1)\n",
    "s = pd.DataFrame(s)\n",
    "s.corr().iloc[:,-1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20.159965\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "median_pred =y.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
